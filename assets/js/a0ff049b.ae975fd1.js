"use strict";(globalThis.webpackChunkdoqumentation=globalThis.webpackChunkdoqumentation||[]).push([[5525],{59188(e,i,a){a.r(i),a.d(i,{assets:()=>s,contentTitle:()=>o,default:()=>u,frontMatter:()=>l,metadata:()=>n,toc:()=>c});const n=JSON.parse('{"id":"tutorials/sml-classification","title":"Classificazione ensemble ibrida quantum-enhanced (workflow di stabilit\xe0 della rete)","description":"Costruite e analizzate un ensemble ibrido quantistico-classico per la classificazione della stabilit\xe0 della rete su QPU IBM utilizzando la Singularity Qiskit Function di Multiverse Computing.","source":"@site/i18n/it/docusaurus-plugin-content-docs/current/tutorials/sml-classification.mdx","sourceDirName":"tutorials","slug":"/tutorials/sml-classification","permalink":"/tutorials/sml-classification","draft":false,"unlisted":false,"editUrl":"https://github.com/JanLahmann/doQumentation/tree/main/docs/tutorials/sml-classification.mdx","tags":[],"version":"current","frontMatter":{"title":"Classificazione ensemble ibrida quantum-enhanced (workflow di stabilit\xe0 della rete)","sidebar_label":"Classificazione ensemble ibrida quantum-enhanced (workflow di stabilit\xe0 della rete)","description":"Costruite e analizzate un ensemble ibrido quantistico-classico per la classificazione della stabilit\xe0 della rete su QPU IBM utilizzando la Singularity Qiskit Function di Multiverse Computing.","notebook_path":"docs/tutorials/sml-classification.ipynb"},"sidebar":"tutorialsSidebar","previous":{"title":"Risolvere il problema Market Split con l\'Iskay Quantum Optimizer di Kipu Quantum","permalink":"/tutorials/solve-market-split-problem-with-iskay-quantum-optimizer"},"next":{"title":"Simulare l\'Ising 2D a campo inclinato con la funzione QESEM","permalink":"/tutorials/qedma-2d-ising-with-qesem"}}');var t=a(74848),r=a(28453);const l={title:"Classificazione ensemble ibrida quantum-enhanced (workflow di stabilit\xe0 della rete)",sidebar_label:"Classificazione ensemble ibrida quantum-enhanced (workflow di stabilit\xe0 della rete)",description:"Costruite e analizzate un ensemble ibrido quantistico-classico per la classificazione della stabilit\xe0 della rete su QPU IBM utilizzando la Singularity Qiskit Function di Multiverse Computing.",notebook_path:"docs/tutorials/sml-classification.ipynb"},o=void 0,s={},c=[{value:"Introduzione",id:"background",level:2},{value:"Requisiti",id:"requirements",level:2},{value:"Setup",id:"setup",level:2},{value:"Scaricare il dataset",id:"download-the-dataset",level:3},{value:"Importare i pacchetti richiesti",id:"import-required-packages",level:3},{value:"Impostare le variabili costanti",id:"set-constant-variables",level:3},{value:"Connettersi a IBM Quantum e caricare la funzione Singularity",id:"connect-to-ibm-quantum-and-load-the-singularity-function",level:3},{value:"Definire le funzioni helper",id:"define-helper-functions",level:3},{value:"Step 1: Mappare gli input classici a un problema quantistico",id:"step-1-map-classical-inputs-to-a-quantum-problem",level:2},{value:"Caricamento e preprocessing dei dati",id:"data-loading-and-preprocessing",level:3},{value:"Baseline classica: riferimento AdaBoost",id:"classical-baseline-adaboost-reference",level:3},{value:"Step 2: Ottimizzare il problema per l&#39;esecuzione su hardware quantistico",id:"step-2-optimize-problem-for-quantum-hardware-execution",level:2},{value:"Step 3: Eseguire utilizzando le primitive Qiskit",id:"step-3-execute-using-qiskit-primitives",level:2},{value:"Baseline",id:"baseline",level:3},{value:"Aumentare il numero di learner",id:"increase-the-number-of-learners",level:3},{value:"Regolarizzazione",id:"regularization",level:3},{value:"Step 4: Post-elaborare e restituire il risultato nel formato classico desiderato",id:"step-4-post-process-and-return-result-in-desired-classical-format",level:2},{value:"Valutare le metriche per ogni configurazione",id:"evaluate-metrics-for-each-configuration",level:3},{value:"Visualizzare le tendenze di qualit\xe0 attraverso le configurazioni",id:"visualize-quality-trends-across-configurations",level:3},{value:"Interpretazione",id:"interpretation",level:3},{value:"Appendice: Benefici di scaling e miglioramenti",id:"appendix-scaling-benefits-and-enhancements",level:2},{value:"Riferimenti",id:"references",level:2},{value:"Sondaggio sul tutorial",id:"tutorial-survey",level:2}];function d(e){const i={a:"a",code:"code",em:"em",h2:"h2",h3:"h3",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components},{OpenInLabBanner:n}=i;return n||function(e,i){throw new Error("Expected "+(i?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("OpenInLabBanner",!0),(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n,{notebookPath:"docs/tutorials/sml-classification.ipynb"}),"\n","\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.em,{children:"Stima dell'utilizzo: 20 minuti di tempo QPU per ogni job su un processore Eagle r3. (NOTA: Questa \xe8 solo una stima. Il vostro tempo di esecuzione pu\xf2 variare.)"})}),"\n",(0,t.jsx)(i.h2,{id:"background",children:"Introduzione"}),"\n",(0,t.jsx)(i.p,{children:"Questo tutorial dimostra un workflow ibrido quantistico-classico che potenzia un ensemble classico con uno step di ottimizzazione quantistica. Utilizzando \"Singularity Machine Learning \u2013 Classification\" di Multiverse Computing (una Qiskit Function), addestriamo un pool di learner convenzionali (ad esempio, alberi decisionali, k-NN, regressione logistica) e poi raffiniamo quel pool con un layer quantistico per migliorare la diversit\xe0 e la generalizzazione. L'obiettivo \xe8 pratico: su un task reale di predizione della stabilit\xe0 della rete, confrontiamo una baseline classica robusta con un'alternativa ottimizzata quantisticamente utilizzando le stesse suddivisioni dei dati, in modo che possiate vedere dove lo step quantistico aiuta e quanto costa."}),"\n",(0,t.jsx)(i.p,{children:"Perch\xe9 questo \xe8 importante: selezionare un buon sottoinsieme da molti weak learner \xe8 un problema combinatorio che cresce rapidamente con la dimensione dell'ensemble. Le euristiche classiche come boosting, bagging e stacking funzionano bene a scale moderate ma possono faticare ad esplorare efficientemente grandi librerie ridondanti di modelli. La funzione integra algoritmi quantistici - in particolare QAOA (e opzionalmente VQE in altre configurazioni) - per esplorare quello spazio in modo pi\xf9 efficace dopo che i learner classici sono stati addestrati, aumentando la possibilit\xe0 di trovare un sottoinsieme compatto e diversificato che generalizza meglio."}),"\n",(0,t.jsx)(i.p,{children:"Fondamentalmente, la scala dei dati non \xe8 limitata dai qubit. Il lavoro pesante sui dati \u2014 preprocessing, addestramento del pool di learner e valutazione \u2014 rimane classico e pu\xf2 gestire milioni di esempi. I qubit determinano solo la dimensione dell'ensemble utilizzata nello step di selezione quantistica. Questo disaccoppiamento \xe8 ci\xf2 che rende l'approccio fattibile sull'hardware odierno: mantenete i workflow familiari di scikit-learn per i dati e l'addestramento dei modelli mentre chiamate lo step quantistico attraverso un'interfaccia action pulita in Qiskit Functions."}),"\n",(0,t.jsx)(i.p,{children:"In pratica, sebbene possano essere forniti all'ensemble diversi tipi di learner (ad esempio, alberi decisionali, regressione logistica o k-NN), gli alberi decisionali tendono a funzionare meglio. L'ottimizzatore favorisce costantemente i membri dell'ensemble pi\xf9 forti\u2014quando vengono forniti learner eterogenei, i modelli pi\xf9 deboli come i regressori lineari vengono tipicamente eliminati a favore di quelli pi\xf9 espressivi come gli alberi decisionali."}),"\n",(0,t.jsxs)(i.p,{children:["Cosa farete qui: preparare e bilanciare il dataset di stabilit\xe0 della rete; stabilire una baseline classica AdaBoost; eseguire diverse configurazioni quantistiche che variano l'ampiezza dell'ensemble e la regolarizzazione; eseguire su simulatori IBM\xae o QPU tramite Qiskit Serverless; e confrontare accuratezza, precisione, recall e F1 su tutte le esecuzioni. Lungo il percorso, utilizzerete il pattern action della funzione (",(0,t.jsx)(i.code,{children:"create"}),", ",(0,t.jsx)(i.code,{children:"fit"}),", ",(0,t.jsx)(i.code,{children:"predict"}),", ",(0,t.jsx)(i.code,{children:"fit_predict"}),", ",(0,t.jsx)(i.code,{children:"create_fit_predict"}),") e i controlli chiave:"]}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:["Tipi di regolarizzazione: ",(0,t.jsx)(i.code,{children:"onsite"})," (\u03bb) per la sparsit\xe0 diretta e ",(0,t.jsx)(i.code,{children:"alpha"})," per un trade-off basato sul rapporto tra termini di interazione e onsite"]}),"\n",(0,t.jsxs)(i.li,{children:["Auto-regolarizzazione: impostate ",(0,t.jsx)(i.code,{children:'regularization="auto"'})," con un rapporto di selezione target per adattare automaticamente la sparsit\xe0"]}),"\n",(0,t.jsx)(i.li,{children:"Opzioni dell'ottimizzatore: simulatore versus QPU, ripetizioni, ottimizzatore classico e le sue opzioni, profondit\xe0 di transpilazione e impostazioni del sampler/estimator runtime"}),"\n"]}),"\n",(0,t.jsx)(i.p,{children:"I benchmark nella documentazione mostrano che l'accuratezza migliora all'aumentare del numero di learner (qubit) su problemi impegnativi, con il classificatore quantistico che eguaglia o supera un ensemble classico comparabile. In questo tutorial, riprodurrete il workflow end-to-end ed esaminerete quando l'aumento dell'ampiezza dell'ensemble o il passaggio alla regolarizzazione adattiva produce un F1 migliore con un utilizzo ragionevole delle risorse. Il risultato \xe8 una visione concreta di come uno step di ottimizzazione quantistica possa complementare, piuttosto che sostituire, l'ensemble learning classico nelle applicazioni reali."}),"\n",(0,t.jsx)(i.h2,{id:"requirements",children:"Requisiti"}),"\n",(0,t.jsx)(i.p,{children:"Prima di iniziare questo tutorial, assicuratevi di avere i seguenti pacchetti installati nel vostro ambiente Python:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:(0,t.jsx)(i.code,{children:"qiskit[visualization]~=2.1.0"})}),"\n",(0,t.jsx)(i.li,{children:(0,t.jsx)(i.code,{children:"qiskit-serverless~=0.24.0"})}),"\n",(0,t.jsx)(i.li,{children:(0,t.jsx)(i.code,{children:"qiskit-ibm-runtime v0.40.1"})}),"\n",(0,t.jsx)(i.li,{children:(0,t.jsx)(i.code,{children:"qiskit-ibm-catalog~=0.8.0"})}),"\n",(0,t.jsx)(i.li,{children:(0,t.jsx)(i.code,{children:"scikit-learn==1.5.2"})}),"\n",(0,t.jsx)(i.li,{children:(0,t.jsx)(i.code,{children:"pandas>=2.0.0,<3.0.0"})}),"\n",(0,t.jsx)(i.li,{children:(0,t.jsx)(i.code,{children:"imbalanced-learn~=0.12.3"})}),"\n"]}),"\n",(0,t.jsx)(i.h2,{id:"setup",children:"Setup"}),"\n",(0,t.jsx)(i.p,{children:"In questa sezione, inizializziamo il client Qiskit Serverless e carichiamo la funzione Singularity Machine Learning \u2013 Classification fornita da Multiverse Computing.\nCon Qiskit Serverless, potete eseguire workflow ibridi quantistico-classici sull'infrastruttura cloud gestita da IBM senza preoccuparvi della gestione delle risorse.\nAvrete bisogno di una chiave API di IBM Quantum Platform e del vostro nome di risorsa cloud (CRN) per autenticarvi e accedere alle Qiskit Functions."}),"\n",(0,t.jsx)(i.h3,{id:"download-the-dataset",children:"Scaricare il dataset"}),"\n",(0,t.jsxs)(i.p,{children:["Per eseguire questo tutorial, utilizziamo un ",(0,t.jsx)(i.strong,{children:"dataset di classificazione della stabilit\xe0 della rete"})," preprocessato contenente letture etichettate di sensori del sistema elettrico.\nLa cella seguente crea automaticamente la struttura di cartelle richiesta e scarica sia i file di training che di test direttamente nel vostro ambiente utilizzando ",(0,t.jsx)(i.code,{children:"wget"}),".\nSe avete gi\xe0 questi file localmente, questo step li sovrascriver\xe0 in modo sicuro per garantire la coerenza della versione."]}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-python",children:"# Added by doQumentation \u2014 installs packages not in the Binder environment\n%pip install -q imbalanced-learn scikit-learn\n"})}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-python",children:'## Download dataset for Grid Stability Classification\n\n# Create data directory if it doesn\'t exist\n!mkdir -p data_tutorial/grid_stability\n\n# Download the training and test sets from the official Qiskit documentation repo\n!wget -q --show-progress -O data_tutorial/grid_stability/train.csv \\\n  https://raw.githubusercontent.com/Qiskit/documentation/main/datasets/tutorials/grid_stability/train.csv\n\n!wget -q --show-progress -O data_tutorial/grid_stability/test.csv \\\n  https://raw.githubusercontent.com/Qiskit/documentation/main/datasets/tutorials/grid_stability/test.csv\n\n# Check the files have been downloaded\n!echo "Dataset files downloaded:"\n!ls -lh data_tutorial/grid_stability/*.csv\n'})}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-text",children:"data_tutorial/grid_ 100%[===================>] 612.94K  --.-KB/s    in 0.01s\ndata_tutorial/grid_ 100%[===================>] 108.19K  --.-KB/s    in 0.006s\nDataset files downloaded:\n-rw-r--r-- 1 coder coder 109K Nov  8 18:50 data_tutorial/grid_stability/test.csv\n-rw-r--r-- 1 coder coder 613K Nov  8 18:50 data_tutorial/grid_stability/train.csv\n"})}),"\n",(0,t.jsx)(i.h3,{id:"import-required-packages",children:"Importare i pacchetti richiesti"}),"\n",(0,t.jsxs)(i.p,{children:["In questa sezione, importiamo tutti i pacchetti Python e i moduli Qiskit utilizzati in tutto il tutorial.\nQuesti includono le librerie scientifiche principali per la gestione dei dati e la valutazione dei modelli - come ",(0,t.jsx)(i.code,{children:"NumPy"}),", ",(0,t.jsx)(i.code,{children:"pandas"})," e ",(0,t.jsx)(i.code,{children:"scikit-learn"})," - insieme agli strumenti di visualizzazione e ai componenti Qiskit per eseguire il modello quantum-enhanced.\nImportiamo anche ",(0,t.jsx)(i.code,{children:"QiskitRuntimeService"})," e ",(0,t.jsx)(i.code,{children:"QiskitFunctionsCatalog"})," per connetterci ai servizi IBM Quantum\xae e accedere alla funzione Singularity Machine Learning."]}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-python",children:'from typing import Tuple\nimport warnings\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom imblearn.over_sampling import RandomOverSampler\nfrom qiskit_ibm_catalog import QiskitFunctionsCatalog\nfrom qiskit_ibm_runtime import QiskitRuntimeService\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.metrics import (\n    accuracy_score,\n    f1_score,\n    precision_score,\n    recall_score,\n)\nfrom sklearn.model_selection import train_test_split\n\nwarnings.filterwarnings("ignore")\n'})}),"\n",(0,t.jsx)(i.h3,{id:"set-constant-variables",children:"Impostare le variabili costanti"}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-python",children:'IBM_TOKEN = ""\nIBM_INSTANCE_TEST = ""\nIBM_INSTANCE_QUANTUM = ""\nFUNCTION_NAME = "multiverse/singularity"\nRANDOM_STATE: int = 123\nTRAIN_PATH = "data_tutorial/grid_stability/train.csv"\nTEST_PATH = "data_tutorial/grid_stability/test.csv"\n'})}),"\n",(0,t.jsx)(i.h3,{id:"connect-to-ibm-quantum-and-load-the-singularity-function",children:"Connettersi a IBM Quantum e caricare la funzione Singularity"}),"\n",(0,t.jsxs)(i.p,{children:["Successivamente, ci autentichiamo con i servizi IBM Quantum e carichiamo la funzione Singularity Machine Learning \u2013 Classification dal Qiskit Functions Catalog.\nIl ",(0,t.jsx)(i.code,{children:"QiskitRuntimeService"})," stabilisce una connessione sicura a IBM Quantum Platform utilizzando il vostro token API e il CRN dell'istanza, permettendo l'accesso ai backend quantistici.\nIl ",(0,t.jsx)(i.code,{children:"QiskitFunctionsCatalog"})," viene poi utilizzato per recuperare la funzione Singularity per nome (",(0,t.jsx)(i.code,{children:'"multiverse/singularity"'}),"), consentendoci di chiamarla successivamente per il calcolo ibrido quantistico-classico.\nSe il setup ha successo, vedrete un messaggio di conferma che indica che la funzione \xe8 stata caricata correttamente."]}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-python",children:'service = QiskitRuntimeService(\n    token=IBM_TOKEN,\n    channel="ibm_quantum_platform",\n    instance=IBM_INSTANCE_QUANTUM,\n)\n\nbackend = service.least_busy()\ncatalog = QiskitFunctionsCatalog(\n    token=IBM_TOKEN,\n    instance=IBM_INSTANCE_TEST,\n    channel="ibm_quantum_platform",\n)\nsingularity = catalog.load(FUNCTION_NAME)\nprint(\n    "Successfully connected to IBM Qiskit Serverless and loaded the Singularity function."\n)\nprint("Catalog:", catalog)\nprint("Singularity function:", singularity)\n'})}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-text",children:"Successfully connected to IBM Qiskit Serverless and loaded the Singularity function.\nCatalog: <QiskitFunctionsCatalog>\nSingularity function: QiskitFunction(multiverse/singularity)\n"})}),"\n",(0,t.jsx)(i.h3,{id:"define-helper-functions",children:"Definire le funzioni helper"}),"\n",(0,t.jsx)(i.p,{children:"Prima di eseguire gli esperimenti principali, definiamo alcune piccole funzioni di utilit\xe0 che semplificano il caricamento dei dati e la valutazione del modello."}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.code,{children:"load_data()"})," legge i file CSV di input in array NumPy, dividendo feature e label per la compatibilit\xe0 con ",(0,t.jsx)(i.code,{children:"scikit-learn"})," e i workflow quantistici."]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.code,{children:"evaluate_predictions()"})," calcola le metriche di performance chiave - accuratezza, precisione, recall e F1-score - e opzionalmente riporta il runtime se vengono fornite informazioni di timing."]}),"\n"]}),"\n",(0,t.jsx)(i.p,{children:"Queste funzioni helper semplificano le operazioni ripetute pi\xf9 avanti nel notebook e garantiscono un reporting coerente delle metriche sia per i classificatori classici che quantistici."}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-python",children:'def load_data(data_path: str) -> Tuple[np.ndarray, np.ndarray]:\n    """Load data from the given path to X and y arrays."""\n    df: pd.DataFrame = pd.read_csv(data_path)\n    return df.iloc[:, :-1].values, df.iloc[:, -1].values\n\ndef evaluate_predictions(predictions, y_true):\n    """Compute and print accuracy, precision, recall, and F1 score."""\n    accuracy = accuracy_score(y_true, predictions)\n    precision = precision_score(y_true, predictions)\n    recall = recall_score(y_true, predictions)\n    f1 = f1_score(y_true, predictions)\n    print("Accuracy:", accuracy)\n    print("Precision:", precision)\n    print("Recall:", recall)\n    print("F1:", f1)\n    return accuracy, precision, recall, f1\n'})}),"\n",(0,t.jsx)(i.h2,{id:"step-1-map-classical-inputs-to-a-quantum-problem",children:"Step 1: Mappare gli input classici a un problema quantistico"}),"\n",(0,t.jsx)(i.p,{children:"Iniziamo preparando il dataset per la sperimentazione ibrida quantistico-classica. L'obiettivo di questo step \xe8 convertire i dati grezzi di stabilit\xe0 della rete in split di training, validazione e test bilanciati che possono essere utilizzati in modo coerente sia dai workflow classici che quantistici. Mantenere split identici garantisce che i confronti di performance successivi siano equi e riproducibili."}),"\n",(0,t.jsx)(i.h3,{id:"data-loading-and-preprocessing",children:"Caricamento e preprocessing dei dati"}),"\n",(0,t.jsx)(i.p,{children:"Per prima cosa carichiamo i file CSV di training e test, creiamo uno split di validazione e bilanciamo il dataset utilizzando il random over-sampling. Il bilanciamento previene il bias verso la classe maggioritaria e fornisce un segnale di apprendimento pi\xf9 stabile sia per i modelli ensemble classici che quantistici."}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-python",children:'# Load and upload the data\nX_train, y_train = load_data(TRAIN_PATH)\nX_test, y_test = load_data(TEST_PATH)\nX_train, X_val, y_train, y_val = train_test_split(\n    X_train, y_train, test_size=0.2, random_state=RANDOM_STATE\n)\n\n# Balance the dataset through over-sampling of the positive class\nros = RandomOverSampler(random_state=RANDOM_STATE)\nX_train_bal, y_train_bal = ros.fit_resample(X_train, y_train)\n\nprint("Shapes:")\nprint("  X_train_bal:", X_train_bal.shape)\nprint("  y_train_bal:", y_train_bal.shape)\nprint("  X_val:", X_val.shape)\nprint("  y_val:", y_val.shape)\nprint("  X_test:", X_test.shape)\nprint("  y_test:", y_test.shape)\n'})}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-text",children:"Shapes:\n  X_train_bal: (5104, 12)\n  y_train_bal: (5104,)\n  X_val: (850, 12)\n  y_val: (850,)\n  X_test: (750, 12)\n  y_test: (750,)\n"})}),"\n",(0,t.jsx)(i.h3,{id:"classical-baseline-adaboost-reference",children:"Baseline classica: riferimento AdaBoost"}),"\n",(0,t.jsx)(i.p,{children:"Prima di eseguire qualsiasi ottimizzazione quantistica, addestriamo una baseline classica robusta - un classificatore AdaBoost standard - sugli stessi dati bilanciati. Questo fornisce un punto di riferimento riproducibile per il confronto successivo, aiutando a quantificare se l'ottimizzazione quantistica migliora la generalizzazione o l'efficienza oltre un ensemble classico ben calibrato."}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-python",children:'# ----- Classical baseline: AdaBoost -----\nbaseline = AdaBoostClassifier(n_estimators=60, random_state=RANDOM_STATE)\nbaseline.fit(X_train_bal, y_train_bal)\nbaseline_pred = baseline.predict(X_test)\nprint("Classical AdaBoost baseline:")\n_ = evaluate_predictions(baseline_pred, y_test)\n'})}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-text",children:"Classical AdaBoost baseline:\nAccuracy: 0.7893333333333333\nPrecision: 1.0\nRecall: 0.7893333333333333\nF1: 0.8822652757078987\n"})}),"\n",(0,t.jsx)(i.h2,{id:"step-2-optimize-problem-for-quantum-hardware-execution",children:"Step 2: Ottimizzare il problema per l'esecuzione su hardware quantistico"}),"\n",(0,t.jsxs)(i.p,{children:["Il task di selezione dell'ensemble \xe8 formulato come un problema di ottimizzazione combinatoria dove ogni weak learner \xe8 una variabile decisionale binaria, e l'obiettivo bilancia l'accuratezza con la sparsit\xe0 attraverso un termine di regolarizzazione. Il ",(0,t.jsx)(i.code,{children:"QuantumEnhancedEnsembleClassifier"})," risolve questo con QAOA sull'hardware IBM, pur consentendo l'esplorazione basata su simulatore. Le ",(0,t.jsx)(i.code,{children:"optimizer_options"})," controllano il loop ibrido: ",(0,t.jsx)(i.code,{children:"simulator=False"})," instrada i circuiti alla QPU selezionata, ",(0,t.jsx)(i.code,{children:"num_solutions"})," aumenta l'ampiezza della ricerca e ",(0,t.jsx)(i.code,{children:"classical_optimizer_options"})," (per l'ottimizzatore classico interno) governano la convergenza; valori intorno a 60 iterazioni sono un buon equilibrio per qualit\xe0 e runtime. Le opzioni di runtime - come la profondit\xe0 moderata del circuito (",(0,t.jsx)(i.code,{children:"reps"}),') e uno sforzo di transpilazione standard - aiutano a garantire prestazioni robuste su diversi dispositivi. La configurazione seguente \xe8 il profilo "best-results" che utilizzeremo per le esecuzioni su hardware; potete anche creare una variante puramente simulata attivando ',(0,t.jsx)(i.code,{children:"simulator=True"})," per eseguire un dry-run del workflow senza consumare tempo QPU."]}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-python",children:'# QAOA / runtime configuration for best results on hardware\noptimizer_options = {\n    "simulator": False,  # set True to test locally without QPU\n    "num_solutions": 100_000,  # broaden search over candidate ensembles\n    "reps": 3,  # QAOA depth (circuit layers)\n    "optimization_level": 3,  # transpilation effort\n    "num_transpiler_runs": 30,  # explore multiple layouts\n    "classical_optimizer": "COBYLA",  # robust default for this landscape\n    "classical_optimizer_options": {\n        "maxiter": 60  # practical convergence budget\n    },\n    # You can pass backend-specific options; leaving None uses least-busy routing\n    "estimator_options": None,\n    "sampler_options": None,\n}\n\nprint("Configured hardware optimization profile:")\nfor key, value in optimizer_options.items():\n    print(f"  {key}: {value}")\n'})}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-text",children:"Configured hardware optimization profile:\n  simulator: False\n  num_solutions: 100000\n  reps: 3\n  optimization_level: 3\n  num_transpiler_runs: 30\n  classical_optimizer: COBYLA\n  classical_optimizer_options: {'maxiter': 60}\n  estimator_options: None\n  sampler_options: None\n"})}),"\n",(0,t.jsx)(i.h2,{id:"step-3-execute-using-qiskit-primitives",children:"Step 3: Eseguire utilizzando le primitive Qiskit"}),"\n",(0,t.jsxs)(i.p,{children:["Ora eseguiamo il workflow completo utilizzando l'action ",(0,t.jsx)(i.code,{children:"create_fit_predict"})," della funzione Singularity per addestrare, ottimizzare e valutare il ",(0,t.jsx)(i.code,{children:"QuantumEnhancedEnsembleClassifier"})," end-to-end sull'infrastruttura IBM. La funzione costruisce l'ensemble, applica l'ottimizzazione quantistica attraverso le primitive Qiskit e restituisce sia le predizioni che i metadati del job (inclusi runtime e utilizzo delle risorse). Lo split dei dati classici dallo Step 1 viene riutilizzato per la riproducibilit\xe0, con i dati di validazione passati attraverso ",(0,t.jsx)(i.code,{children:"fit_params"})," in modo che l'ottimizzazione possa calibrare gli iperparametri internamente mantenendo intatto il test set trattenuto."]}),"\n",(0,t.jsxs)(i.p,{children:["In questo step, esploriamo diverse configurazioni dell'ensemble quantistico per comprendere come i parametri chiave - specificamente ",(0,t.jsx)(i.code,{children:"num_learners"})," e ",(0,t.jsx)(i.code,{children:"regularization"})," - influenzano sia la qualit\xe0 dei risultati che l'utilizzo della QPU."]}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.code,{children:"num_learners"})," determina l'ampiezza dell'ensemble (e implicitamente, il numero di qubit), influenzando la capacit\xe0 del modello e il costo computazionale."]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.code,{children:"regularization"})," controlla la sparsit\xe0 e l'overfitting, determinando quanti learner rimangono attivi dopo l'ottimizzazione."]}),"\n"]}),"\n",(0,t.jsx)(i.p,{children:"Variando questi parametri, possiamo vedere come l'ampiezza dell'ensemble e la regolarizzazione interagiscono: aumentare l'ampiezza tipicamente migliora l'F1 ma costa pi\xf9 tempo QPU, mentre una regolarizzazione pi\xf9 forte o adattiva pu\xf2 migliorare la generalizzazione con circa la stessa impronta hardware. Le prossime sottosezioni illustrano tre configurazioni rappresentative per illustrare questi effetti."}),"\n",(0,t.jsx)(i.h3,{id:"baseline",children:"Baseline"}),"\n",(0,t.jsxs)(i.p,{children:["Questa configurazione utilizza ",(0,t.jsx)(i.code,{children:"num_learners = 10"})," e ",(0,t.jsx)(i.code,{children:"regularization = 7"}),"."]}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.code,{children:"num_learners"})," controlla l'ampiezza dell'ensemble \u2014 effettivamente il numero di weak learner combinati e, sull'hardware quantistico, il ",(0,t.jsx)(i.strong,{children:"numero di qubit richiesti"}),". Un valore maggiore espande lo spazio di ricerca combinatoria e pu\xf2 migliorare accuratezza e recall, ma aumenta anche la larghezza del circuito, il tempo di compilazione e l'utilizzo complessivo della QPU."]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.code,{children:"regularization"}),' imposta la forza della penalit\xe0 per l\'inclusione di learner aggiuntivi. Con la regolarizzazione "onsite" predefinita, valori pi\xf9 alti impongono una sparsit\xe0 pi\xf9 forte (meno learner mantenuti), mentre valori pi\xf9 bassi permettono ensemble pi\xf9 complessi.']}),"\n"]}),"\n",(0,t.jsx)(i.p,{children:"Questo setup fornisce una baseline a basso costo, mostrando come si comporta un ensemble piccolo prima di scalare l'ampiezza o calibrare la sparsit\xe0."}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-python",children:"# Problem scale and regularization\nNUM_LEARNERS = 10\nREGULARIZATION = 7\n"})}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-python",children:'# ----- Quantum-enhanced ensemble on IBM hardware -----\nprint("\\n-- Submitting quantum-enhanced ensemble job --")\njob_1 = singularity.run(\n    action="create_fit_predict",\n    name="grid_stability_qeec",\n    quantum_classifier="QuantumEnhancedEnsembleClassifier",\n    num_learners=NUM_LEARNERS,\n    regularization=REGULARIZATION,\n    optimizer_options=optimizer_options,  # from Step 2\n    backend_name=backend,  # least-busy compatible backend\n    instance=IBM_INSTANCE_QUANTUM,\n    random_state=RANDOM_STATE,\n    X_train=X_train_bal,\n    y_train=y_train_bal,\n    X_test=X_test,\n    fit_params={"validation_data": (X_val, y_val)},\n    options={"save": False},\n)\nresult_1 = job_1.result()\nprint("Action status:", result_1.get("status"))\nprint("Action message:", result_1.get("message"))\nprint("Metadata:", result_1.get("metadata"))\nqeec_pred_job_1 = np.array(result_1["data"]["predictions"])\n_ = evaluate_predictions(qeec_pred_job_1, y_test)\n'})}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-text",children:"-- Submitting quantum-enhanced ensemble job --\nAction status: ok\nAction message: Classifier created, fitted, and predicted.\nMetadata: {'resource_usage': {'RUNNING: MAPPING': {'CPU_TIME': 267.05158376693726}, 'RUNNING: WAITING_QPU': {'CPU_TIME': 3336.8785166740417}, 'RUNNING: POST_PROCESSING': {'CPU_TIME': 152.4274561405182}, 'RUNNING: EXECUTING_QPU': {'QPU_TIME': 1550.1889700889587}}}\nAccuracy: 0.868\nPrecision: 1.0\nRecall: 0.868\nF1: 0.9293361884368309\n"})}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-python",children:'status_1 = job_1.status()\nprint("\\nQuantum job status:", status_1)\n'})}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-text",children:"Quantum job status: DONE\n"})}),"\n",(0,t.jsx)(i.h3,{id:"increase-the-number-of-learners",children:"Aumentare il numero di learner"}),"\n",(0,t.jsxs)(i.p,{children:["Qui aumentiamo ",(0,t.jsx)(i.code,{children:"num_learners"})," da 10 \u2192 30 mantenendo ",(0,t.jsx)(i.code,{children:"regularization = 7"}),"."]}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Un maggior numero di learner espande lo spazio delle ipotesi, consentendo al modello di catturare pattern pi\xf9 sottili, il che pu\xf2 incrementare modestamente l'F1."}),"\n",(0,t.jsx)(i.li,{children:"Nella maggior parte dei casi, la differenza di tempo di esecuzione tra 10 e 30 learner non \xe8 sostanziale, indicando che l'ampiezza aggiuntiva del circuito non aumenta significativamente il costo di esecuzione."}),"\n",(0,t.jsxs)(i.li,{children:["Il miglioramento della qualit\xe0 segue ancora una ",(0,t.jsx)(i.em,{children:"curva a rendimenti decrescenti"}),": i guadagni iniziali compaiono man mano che l'ensemble cresce, ma si appiattiscono poich\xe9 i learner aggiuntivi contribuiscono con meno informazioni nuove."]}),"\n"]}),"\n",(0,t.jsx)(i.p,{children:"Questo esperimento evidenzia il trade-off tra qualit\xe0 ed efficienza \u2014 aumentare l'ampiezza dell'ensemble pu\xf2 offrire piccoli guadagni di accuratezza senza una penalit\xe0 significativa nel tempo di esecuzione, a seconda delle condizioni del backend e della transpilazione."}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-python",children:"# Problem scale and regularization\nNUM_LEARNERS = 30\nREGULARIZATION = 7\n"})}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-python",children:'# ----- Quantum-enhanced ensemble on IBM hardware -----\nprint("\\n-- Submitting quantum-enhanced ensemble job --")\njob_2 = singularity.run(\n    action="create_fit_predict",\n    name="grid_stability_qeec",\n    quantum_classifier="QuantumEnhancedEnsembleClassifier",\n    num_learners=NUM_LEARNERS,\n    regularization=REGULARIZATION,\n    optimizer_options=optimizer_options,  # from Step 2\n    backend_name=backend,  # least-busy compatible backend\n    instance=IBM_INSTANCE_QUANTUM,\n    random_state=RANDOM_STATE,\n    X_train=X_train_bal,\n    y_train=y_train_bal,\n    X_test=X_test,\n    fit_params={"validation_data": (X_val, y_val)},\n    options={"save": False},\n)\nresult_2 = job_2.result()\nprint("Action status:", result_2.get("status"))\nprint("Action message:", result_2.get("message"))\nprint("QPU Time:", result_2.get("metadata"))\nqeec_pred_job_2 = np.array(result_2["data"]["predictions"])\n_ = evaluate_predictions(qeec_pred_job_2, y_test)\n'})}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-text",children:"-- Submitting quantum-enhanced ensemble job --\nAction status: ok\nAction message: Classifier created, fitted, and predicted.\nQPU Time: {'resource_usage': {'RUNNING: MAPPING': {'CPU_TIME': 680.2116754055023}, 'RUNNING: WAITING_QPU': {'CPU_TIME': 80.80395102500916}, 'RUNNING: POST_PROCESSING': {'CPU_TIME': 154.4466371536255}, 'RUNNING: EXECUTING_QPU': {'QPU_TIME': 1095.822762966156}}}\nAccuracy: 0.8946666666666667\nPrecision: 1.0\nRecall: 0.8946666666666667\nF1: 0.944405348346235\n"})}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-python",children:'status_2 = job_2.status()\nprint("\\nQuantum job status:", status_2)\n'})}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-text",children:"Quantum job status: DONE\n"})}),"\n",(0,t.jsx)(i.h3,{id:"regularization",children:"Regolarizzazione"}),"\n",(0,t.jsxs)(i.p,{children:["In questa configurazione, aumentiamo a ",(0,t.jsx)(i.code,{children:"num_learners = 60"})," e introduciamo la regolarizzazione adattiva per gestire la sparsit\xe0 in modo pi\xf9 intuitivo."]}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:["Con ",(0,t.jsx)(i.code,{children:'regularization = "auto"'}),", l'ottimizzatore trova automaticamente un'intensit\xe0 di regolarizzazione adeguata che seleziona approssimativamente ",(0,t.jsx)(i.code,{children:"regularization_ratio * num_learners"})," weak learner per l'ensemble finale, invece di fissare manualmente la penalit\xe0. Questo fornisce un'interfaccia pi\xf9 conveniente per gestire l'equilibrio tra sparsit\xe0 e dimensione dell'ensemble."]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.code,{children:'regularization_type = "alpha"'})," definisce come viene applicata la penalit\xe0. A differenza di ",(0,t.jsx)(i.code,{children:"onsite"}),", che \xe8 illimitato ",(0,t.jsx)(i.code,{children:"[0, \u221e]"}),", ",(0,t.jsx)(i.code,{children:"alpha"})," \xe8 limitato tra ",(0,t.jsx)(i.code,{children:"[0, 1]"}),", rendendolo pi\xf9 facile da regolare e interpretare. Il parametro controlla il trade-off tra penalit\xe0 individuali e a coppie, offrendo un intervallo di configurazione pi\xf9 fluido."]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.code,{children:"regularization_desired_ratio \u2248 0.82"})," specifica la proporzione target di learner da mantenere attivi dopo la regolarizzazione \u2014 qui, circa l'82% dei learner viene mantenuto, eliminando automaticamente il 18% pi\xf9 debole."]}),"\n"]}),"\n",(0,t.jsx)(i.p,{children:"Sebbene la regolarizzazione adattiva semplifichi la configurazione e aiuti a mantenere un ensemble bilanciato, non garantisce necessariamente prestazioni migliori o pi\xf9 stabili. La qualit\xe0 effettiva dipende dalla selezione di un parametro di regolarizzazione appropriato, e la sua messa a punto tramite convalida incrociata pu\xf2 essere computazionalmente costosa. Il vantaggio principale risiede in una migliore usabilit\xe0 e interpretabilit\xe0 piuttosto che in guadagni diretti di accuratezza."}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-python",children:'# Problem scale and regularization\nNUM_LEARNERS = 60\nREGULARIZATION = "auto"\nREGULARIZATION_TYPE = "alpha"\nREGULARIZATION_RATIO = 0.82\n'})}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-python",children:'# ----- Quantum-enhanced ensemble on IBM hardware -----\nprint("\\n-- Submitting quantum-enhanced ensemble job --")\njob_3 = singularity.run(\n    action="create_fit_predict",\n    name="grid_stability_qeec",\n    quantum_classifier="QuantumEnhancedEnsembleClassifier",\n    num_learners=NUM_LEARNERS,\n    regularization=REGULARIZATION,\n    regularization_type=REGULARIZATION_TYPE,\n    regularization_desired_ratio=REGULARIZATION_RATIO,\n    optimizer_options=optimizer_options,  # from Step 2\n    backend_name=backend,  # least-busy compatible backend\n    instance=IBM_INSTANCE_QUANTUM,\n    random_state=RANDOM_STATE,\n    X_train=X_train_bal,\n    y_train=y_train_bal,\n    X_test=X_test,\n    fit_params={"validation_data": (X_val, y_val)},\n    options={"save": False},\n)\nresult_3 = job_3.result()\nprint("Action status:", result_3.get("status"))\nprint("Action message:", result_3.get("message"))\nprint("Metadata:", result_3.get("metadata"))\nqeec_pred_job_3 = np.array(result_3["data"]["predictions"])\n_ = evaluate_predictions(qeec_pred_job_3, y_test)\n'})}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-text",children:"-- Submitting quantum-enhanced ensemble job --\nAction status: ok\nAction message: Classifier created, fitted, and predicted.\nMetadata: {'resource_usage': {'RUNNING: MAPPING': {'CPU_TIME': 1387.7451872825623}, 'RUNNING: WAITING_QPU': {'CPU_TIME': 95.41597843170166}, 'RUNNING: POST_PROCESSING': {'CPU_TIME': 171.78878355026245}, 'RUNNING: EXECUTING_QPU': {'QPU_TIME': 1146.5584812164307}}}\nAccuracy: 0.908\nPrecision: 1.0\nRecall: 0.908\nF1: 0.9517819706498952\n"})}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-python",children:'status_3 = job_3.status()\nprint("\\nQuantum job status:", status_3)\n'})}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-text",children:"Quantum job status: DONE\n"})}),"\n",(0,t.jsx)(i.h2,{id:"step-4-post-process-and-return-result-in-desired-classical-format",children:"Step 4: Post-elaborare e restituire il risultato nel formato classico desiderato"}),"\n",(0,t.jsxs)(i.p,{children:["Ora post-elaboriamo gli output sia delle esecuzioni classiche che quantistiche, convertendoli in un formato coerente per la valutazione a valle. Questo passo confronta la qualit\xe0 predittiva utilizzando metriche standard - accuratezza, precisione, recall e F1 - e analizza come l'ampiezza dell'ensemble (",(0,t.jsx)(i.code,{children:"num_learners"}),") e il controllo della sparsit\xe0 (",(0,t.jsx)(i.code,{children:"regularization"}),") influenzino sia le prestazioni che il comportamento computazionale."]}),"\n",(0,t.jsxs)(i.p,{children:["La baseline classica di AdaBoost fornisce un riferimento compatto e stabile per l'apprendimento su piccola scala. Funziona bene con ensemble limitati e un overhead di calcolo trascurabile, riflettendo la forza del boosting tradizionale quando lo spazio delle ipotesi \xe8 ancora trattabile. Le configurazioni quantistiche (",(0,t.jsx)(i.code,{children:"qeec_pred_job_1"}),", ",(0,t.jsx)(i.code,{children:"qeec_pred_job_2"})," e ",(0,t.jsx)(i.code,{children:"qeec_pred_job_3"}),") estendono questa baseline incorporando il processo di selezione dell'ensemble all'interno di un ciclo di ottimizzazione quantistica variazionale. Questo consente al sistema di esplorare simultaneamente in sovrapposizione sottoinsiemi esponenzialmente grandi di learner, affrontando la natura combinatoria della selezione dell'ensemble in modo pi\xf9 efficiente man mano che la scala aumenta."]}),"\n",(0,t.jsxs)(i.p,{children:["I risultati mostrano che aumentare ",(0,t.jsx)(i.code,{children:"num_learners"})," da 10 a 30 migliora recall e F1, confermando che un ensemble pi\xf9 ampio cattura interazioni pi\xf9 ricche tra i weak learner. Il guadagno \xe8 sublineare sull'hardware attuale - ogni learner aggiuntivo produce incrementi di accuratezza pi\xf9 piccoli - ma il comportamento di scaling sottostante rimane favorevole perch\xe9 l'ottimizzatore quantistico pu\xf2 cercare spazi di configurazione pi\xf9 ampi senza l'esplosione esponenziale tipica della selezione classica dei sottoinsiemi. La regolarizzazione introduce ulteriori sfumature: un \u03bb=7 fisso impone sparsit\xe0 coerente e stabilizza la convergenza, mentre la \u03b1-regolarizzazione adattiva regola automaticamente la sparsit\xe0 in base alle correlazioni tra i learner. Questa potatura dinamica spesso ottiene un F1 leggermente pi\xf9 alto per la stessa ampiezza di qubit, bilanciando complessit\xe0 del modello e generalizzazione."]}),"\n",(0,t.jsxs)(i.p,{children:['Quando confrontate direttamente con la baseline AdaBoost, la configurazione quantistica pi\xf9 piccola (L=10) riproduce un\'accuratezza simile, convalidando la correttezza della pipeline ibrida. Ad ampiezze maggiori, le varianti quantistiche - specialmente con auto-regolarizzazione - iniziano a superare modestamente la baseline classica, mostrando recall e F1 migliorati senza una crescita lineare del costo computazionale. Questi miglioramenti non indicano un "vantaggio quantistico" immediato ma piuttosto ',(0,t.jsx)(i.strong,{children:"efficienza di scaling"}),": l'ottimizzatore quantistico mantiene prestazioni trattabili man mano che l'ensemble si espande, laddove un approccio classico affronterebbe una crescita esponenziale nella complessit\xe0 di selezione dei sottoinsiemi."]}),"\n",(0,t.jsx)(i.p,{children:"In pratica:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:["Utilizzate la ",(0,t.jsx)(i.strong,{children:"baseline classica"})," per una validazione rapida e benchmarking su dataset piccoli."]}),"\n",(0,t.jsxs)(i.li,{children:["Applicate gli ",(0,t.jsx)(i.strong,{children:"ensemble quantistici"})," quando l'ampiezza del modello o la complessit\xe0 delle feature crescono \u2014 la ricerca basata su QAOA scala pi\xf9 agevolmente in quei regimi."]}),"\n",(0,t.jsxs)(i.li,{children:["Impiegate la ",(0,t.jsx)(i.strong,{children:"\u03b1-regolarizzazione adattiva"})," per mantenere sparsit\xe0 e generalizzazione senza aumentare l'ampiezza del circuito."]}),"\n",(0,t.jsx)(i.li,{children:"Monitorate il tempo QPU e la profondit\xe0 per bilanciare i guadagni di qualit\xe0 rispetto ai vincoli dell'hardware a breve termine."}),"\n"]}),"\n",(0,t.jsx)(i.p,{children:"Nel complesso, questi esperimenti dimostrano che gli ensemble ottimizzati quantisticamente complementano i metodi classici: riproducono l'accuratezza della baseline a piccola scala offrendo al contempo un percorso verso uno scaling efficiente su problemi di apprendimento combinatorio pi\xf9 grandi. Man mano che l'hardware migliora, questi vantaggi di scaling dovrebbero amplificarsi, estendendo la dimensione e la profondit\xe0 realizzabili dei modelli basati su ensemble oltre ci\xf2 che \xe8 classicamente praticabile."}),"\n",(0,t.jsx)(i.h3,{id:"evaluate-metrics-for-each-configuration",children:"Valutare le metriche per ogni configurazione"}),"\n",(0,t.jsxs)(i.p,{children:["Ora valutiamo tutte le configurazioni - la baseline classica di AdaBoost e i tre ensemble quantistici - utilizzando l'helper ",(0,t.jsx)(i.code,{children:"evaluate_predictions"})," per calcolare accuratezza, precisione, recall e F1 sullo stesso set di test. Questo confronto chiarisce come l'ottimizzazione quantistica scala rispetto all'approccio classico: a piccole ampiezze, entrambi si comportano in modo simile; man mano che gli ensemble crescono, il metodo quantistico pu\xf2 esplorare spazi di ipotesi pi\xf9 grandi in modo pi\xf9 efficiente. La tabella risultante cattura queste tendenze in una forma coerente e quantitativa."]}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-python",children:'results = []\n\n# Classical baseline\nacc_b, prec_b, rec_b, f1_b = evaluate_predictions(baseline_pred, y_test)\nresults.append(\n    {\n        "Config": "AdaBoost (Classical)",\n        "Accuracy": acc_b,\n        "Precision": prec_b,\n        "Recall": rec_b,\n        "F1": f1_b,\n    }\n)\n\n# Quantum runs\nfor label, preds in [\n    ("QEEC L=10, reg=7", qeec_pred_job_1),\n    ("QEEC L=30, reg=7", qeec_pred_job_2),\n    (f"QEEC L=60, reg=auto (\u03b1={REGULARIZATION_RATIO})", qeec_pred_job_3),\n]:\n    acc, prec, rec, f1 = evaluate_predictions(preds, y_test)\n    results.append(\n        {\n            "Config": label,\n            "Accuracy": acc,\n            "Precision": prec,\n            "Recall": rec,\n            "F1": f1,\n        }\n    )\n\ndf_results = pd.DataFrame(results)\ndf_results\n'})}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-text",children:"Accuracy: 0.7893333333333333\nPrecision: 1.0\nRecall: 0.7893333333333333\nF1: 0.8822652757078987\nAccuracy: 0.868\nPrecision: 1.0\nRecall: 0.868\nF1: 0.9293361884368309\nAccuracy: 0.8946666666666667\nPrecision: 1.0\nRecall: 0.8946666666666667\nF1: 0.944405348346235\nAccuracy: 0.908\nPrecision: 1.0\nRecall: 0.908\nF1: 0.9517819706498952\n"})}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-text",children:"Config  Accuracy  Precision    Recall        F1\n0          AdaBoost (Classical)  0.789333        1.0  0.789333  0.882265\n1              QEEC L=10, reg=7  0.868000        1.0  0.868000  0.929336\n2              QEEC L=30, reg=7  0.894667        1.0  0.894667  0.944405\n3  QEEC L=60, reg=auto (\u03b1=0.82)  0.908000        1.0  0.908000  0.951782\n"})}),"\n",(0,t.jsx)(i.h3,{id:"visualize-quality-trends-across-configurations",children:"Visualizzare le tendenze di qualit\xe0 attraverso le configurazioni"}),"\n",(0,t.jsxs)(i.p,{children:["Il grafico a barre raggruppate qui sotto confronta ",(0,t.jsx)(i.strong,{children:"Accuracy"})," e ",(0,t.jsx)(i.strong,{children:"F1"})," attraverso la baseline classica e gli ensemble quantistici (",(0,t.jsx)(i.code,{children:"L=10"}),", ",(0,t.jsx)(i.code,{children:"L=30"})," e ",(0,t.jsx)(i.code,{children:"L=60 auto-\u03b1"}),"). Illustra come l'accuratezza si stabilizza mentre F1 migliora gradualmente man mano che l'ampiezza dell'ensemble quantistico aumenta, dimostrando che il metodo ibrido sostiene lo scaling delle prestazioni senza la crescita esponenziale dei costi tipica della selezione classica dei sottoinsiemi."]}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-python",children:'x = np.arange(len(df_results))\nwidth = 0.35\nplt.figure(figsize=(7.6, 4.6))\nplt.bar(x - width / 2, df_results["Accuracy"], width=width, label="Accuracy")\nplt.bar(x + width / 2, df_results["F1"], width=width, label="F1")\nplt.xticks(x, df_results["Config"], rotation=10)\nplt.ylabel("Score")\nplt.title("Classical vs Quantum ensemble performance")\nplt.legend()\nplt.ylim(0, 1.0)\nplt.tight_layout()\nplt.show()\n'})}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"Output of the previous code cell",src:a(17991).A+"",width:"742",height:"449"})}),"\n",(0,t.jsx)(i.h3,{id:"interpretation",children:"Interpretazione"}),"\n",(0,t.jsx)(i.p,{children:"Il grafico conferma il pattern di scaling atteso. L'AdaBoost classico funziona bene per ensemble pi\xf9 piccoli ma diventa sempre pi\xf9 costoso da scalare man mano che il numero di weak learner cresce, perch\xe9 il suo problema di selezione dei sottoinsiemi si espande in modo combinatoriale. I modelli ottimizzati quantisticamente replicano l'accuratezza classica a basse ampiezze e iniziano a superarla man mano che la dimensione dell'ensemble aumenta, specialmente con la \u03b1-regolarizzazione adattiva. Questo riflette la capacit\xe0 dell'ottimizzatore quantistico di campionare e valutare molti sottoinsiemi candidati in parallelo attraverso la sovrapposizione, mantenendo una ricerca trattabile anche ad ampiezze pi\xf9 elevate. Sebbene l'overhead dell'hardware attuale compensi alcuni dei guadagni teorici, la tendenza illustra il vantaggio di efficienza di scaling della formulazione quantistica. In termini pratici, il metodo classico rimane preferibile per benchmark leggeri, mentre gli ensemble ottimizzati quantisticamente diventano vantaggiosi man mano che la dimensionalit\xe0 del modello e la dimensione dell'ensemble si espandono, offrendo trade-off migliori tra accuratezza, generalizzazione e crescita computazionale."}),"\n",(0,t.jsx)(i.h2,{id:"appendix-scaling-benefits-and-enhancements",children:"Appendice: Benefici di scaling e miglioramenti"}),"\n",(0,t.jsxs)(i.p,{children:["Il vantaggio di scalabilit\xe0 del ",(0,t.jsx)(i.code,{children:"QuantumEnhancedEnsembleClassifier"})," deriva da come il processo di selezione dell'ensemble si mappa all'ottimizzazione quantistica.\nI metodi classici di apprendimento ensemble, come AdaBoost o le foreste casuali, diventano computazionalmente costosi man mano che il numero di weak learner aumenta perch\xe9 la selezione del sottoinsieme ottimale \xe8 un problema combinatoriale che scala esponenzialmente."]}),"\n",(0,t.jsx)(i.p,{children:"Al contrario, la formulazione quantistica \u2014 implementata qui tramite il Quantum Approximate Optimization Algorithm (QAOA) \u2014 pu\xf2 esplorare questi spazi di ricerca esponenzialmente grandi in modo pi\xf9 efficiente valutando configurazioni multiple in sovrapposizione.\nDi conseguenza, il tempo di addestramento non cresce significativamente con il numero di learner, consentendo al modello di rimanere efficiente anche quando l'ampiezza dell'ensemble aumenta."}),"\n",(0,t.jsx)(i.p,{children:"Sebbene l'hardware attuale introduca del rumore e limitazioni di profondit\xe0, questo workflow dimostra un approccio ibrido a breve termine in cui componenti classiche e quantistiche cooperano: l'ottimizzatore quantistico fornisce un migliore paesaggio di inizializzazione per il ciclo classico, migliorando la convergenza e la qualit\xe0 finale del modello.\nMan mano che i processori quantistici evolvono, questi benefici di scalabilit\xe0 dovrebbero estendersi a dataset pi\xf9 grandi, ensemble pi\xf9 ampi e profondit\xe0 di circuito maggiori."}),"\n",(0,t.jsx)(i.h2,{id:"references",children:"Riferimenti"}),"\n",(0,t.jsxs)(i.ol,{children:["\n",(0,t.jsx)(i.li,{children:(0,t.jsx)(i.a,{href:"/guides/functions",children:"Introduction to Qiskit Functions"})}),"\n",(0,t.jsx)(i.li,{children:(0,t.jsx)(i.a,{href:"/guides/multiverse-computing-singularity",children:"Multiverse Computing Singularity Machine Learning"})}),"\n"]}),"\n",(0,t.jsx)(i.h2,{id:"tutorial-survey",children:"Sondaggio sul tutorial"}),"\n",(0,t.jsx)(i.p,{children:"Per favore, dedicate un minuto a fornire un feedback su questo tutorial. Le vostre opinioni ci aiuteranno a migliorare i nostri contenuti e l'esperienza utente."})]})}function u(e={}){const{wrapper:i}={...(0,r.R)(),...e.components};return i?(0,t.jsx)(i,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},17991(e,i,a){a.d(i,{A:()=>n});const n="data:image/avif;base64,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"},28453(e,i,a){a.d(i,{R:()=>l,x:()=>o});var n=a(96540);const t={},r=n.createContext(t);function l(e){const i=n.useContext(r);return n.useMemo(function(){return"function"==typeof e?e(i):{...i,...e}},[i,e])}function o(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:l(e.components),n.createElement(r.Provider,{value:i},e.children)}}}]);